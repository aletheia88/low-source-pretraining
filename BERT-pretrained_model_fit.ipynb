{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = 'train_val_data.csv'\n",
    "token_dict = get_token_freq(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x33': 4504,\n",
       " 'x41': 4212,\n",
       " 'x160': 4716,\n",
       " 'x195': 6819,\n",
       " 'x150': 6239,\n",
       " 'x51': 4174,\n",
       " 'x122': 4288,\n",
       " 'x18': 2701,\n",
       " 'x154': 2889,\n",
       " 'x80': 2466,\n",
       " 'x183': 746,\n",
       " 'x134': 814,\n",
       " 'x155': 701,\n",
       " 'x5': 2387,\n",
       " 'x206': 9981,\n",
       " 'x188': 8060,\n",
       " 'x24': 9302,\n",
       " 'x1': 3664,\n",
       " 'x141': 5389,\n",
       " 'x149': 5778,\n",
       " 'x91': 3827,\n",
       " 'x211': 1782,\n",
       " 'x76': 1801,\n",
       " 'x193': 1086,\n",
       " 'x213': 594,\n",
       " 'x37': 983,\n",
       " 'x16': 6708,\n",
       " 'x158': 1649,\n",
       " 'x64': 6497,\n",
       " 'x62': 1348,\n",
       " 'x38': 1775,\n",
       " 'x205': 3112,\n",
       " 'x88': 8509,\n",
       " 'x176': 5984,\n",
       " 'x19': 12640,\n",
       " 'x223': 4593,\n",
       " 'x6': 6088,\n",
       " 'x81': 2968,\n",
       " 'x56': 608,\n",
       " 'x142': 5508,\n",
       " 'x98': 433,\n",
       " 'x210': 2661,\n",
       " 'x97': 1134,\n",
       " 'x219': 1216,\n",
       " 'x83': 5380,\n",
       " 'x7': 5019,\n",
       " 'x121': 454,\n",
       " 'x153': 166,\n",
       " 'x197': 2532,\n",
       " 'x185': 8713,\n",
       " 'x225': 6572,\n",
       " 'x69': 2757,\n",
       " 'x42': 8169,\n",
       " 'x244': 171,\n",
       " 'x68': 1380,\n",
       " 'x212': 1940,\n",
       " 'x180': 4343,\n",
       " 'x192': 3670,\n",
       " 'x104': 1474,\n",
       " 'x231': 4269,\n",
       " 'x54': 3593,\n",
       " 'x113': 826,\n",
       " 'x170': 2045,\n",
       " 'x146': 8966,\n",
       " 'x106': 1755,\n",
       " 'x125': 1298,\n",
       " 'x11': 2375,\n",
       " 'x71': 6510,\n",
       " 'x187': 2165,\n",
       " 'x47': 6936,\n",
       " 'x228': 474,\n",
       " 'x203': 3080,\n",
       " 'x49': 8223,\n",
       " 'x105': 1167,\n",
       " 'x30': 1580,\n",
       " 'x253': 6741,\n",
       " 'x92': 2279,\n",
       " 'x65': 5800,\n",
       " 'x119': 16059,\n",
       " 'x166': 3641,\n",
       " 'x177': 576,\n",
       " 'x220': 6359,\n",
       " 'x67': 1891,\n",
       " 'x189': 4497,\n",
       " 'x171': 3309,\n",
       " 'x40': 8365,\n",
       " 'x230': 1001,\n",
       " 'x115': 216,\n",
       " 'x72': 1319,\n",
       " 'x15': 1457,\n",
       " 'x12': 1026,\n",
       " 'x208': 1747,\n",
       " 'x55': 2705,\n",
       " 'x52': 3236,\n",
       " 'x23': 6095,\n",
       " 'x85': 10627,\n",
       " 'x130': 1096,\n",
       " 'x229': 5861,\n",
       " 'x221': 3634,\n",
       " 'x178': 557,\n",
       " 'x59': 2276,\n",
       " 'x214': 1237,\n",
       " 'x126': 796,\n",
       " 'x53': 3798,\n",
       " 'x44': 297,\n",
       " 'x144': 3435,\n",
       " 'x58': 1543,\n",
       " 'x108': 775,\n",
       " 'x242': 367,\n",
       " 'x252': 1623,\n",
       " 'x20': 2450,\n",
       " 'x179': 2176,\n",
       " 'x13': 9250,\n",
       " 'x143': 566,\n",
       " 'x70': 7280,\n",
       " 'x110': 3800,\n",
       " 'x120': 9161,\n",
       " 'x169': 7462,\n",
       " 'x25': 8339,\n",
       " 'x235': 5602,\n",
       " 'x251': 3806,\n",
       " 'x200': 6328,\n",
       " 'x241': 5979,\n",
       " 'x127': 7116,\n",
       " 'x101': 974,\n",
       " 'x109': 443,\n",
       " 'x114': 1296,\n",
       " 'x174': 2829,\n",
       " 'x190': 896,\n",
       " 'x162': 1171,\n",
       " 'x50': 8820,\n",
       " 'x138': 998,\n",
       " 'x78': 614,\n",
       " 'x243': 3617,\n",
       " 'x45': 1750,\n",
       " 'x3': 2192,\n",
       " 'x4': 3925,\n",
       " 'x156': 1125,\n",
       " 'x82': 4780,\n",
       " 'x36': 15414,\n",
       " 'x84': 1202,\n",
       " 'x163': 5611,\n",
       " 'x31': 3620,\n",
       " 'x60': 3809,\n",
       " 'x202': 1028,\n",
       " 'x29': 5151,\n",
       " 'x164': 2165,\n",
       " 'x184': 7212,\n",
       " 'x8': 9205,\n",
       " 'x145': 4173,\n",
       " 'x218': 646,\n",
       " 'x137': 84,\n",
       " 'x165': 277,\n",
       " 'x79': 10740,\n",
       " 'x93': 9865,\n",
       " 'x191': 2349,\n",
       " 'x43': 3327,\n",
       " 'x217': 2681,\n",
       " 'x233': 4807,\n",
       " 'x35': 7704,\n",
       " 'x175': 6801,\n",
       " 'x90': 4549,\n",
       " 'x207': 480,\n",
       " 'x224': 1123,\n",
       " 'x96': 6018,\n",
       " 'x89': 4805,\n",
       " 'x157': 9696,\n",
       " 'x14': 3604,\n",
       " 'x234': 1126,\n",
       " 'x204': 1641,\n",
       " 'x238': 3413,\n",
       " 'x48': 3520,\n",
       " 'x21': 436,\n",
       " 'x198': 605,\n",
       " 'x32': 3624,\n",
       " 'x246': 1225,\n",
       " 'x172': 4081,\n",
       " 'x173': 667,\n",
       " 'x57': 384,\n",
       " 'x254': 3529,\n",
       " 'x116': 1047,\n",
       " 'x77': 4942,\n",
       " 'x152': 1201,\n",
       " 'x248': 531,\n",
       " 'x245': 988,\n",
       " 'x186': 637,\n",
       " 'x199': 2242,\n",
       " 'x215': 820,\n",
       " 'x239': 780,\n",
       " 'x168': 885,\n",
       " 'x133': 2295,\n",
       " 'x227': 518,\n",
       " 'x17': 2676,\n",
       " 'x118': 255,\n",
       " 'x209': 1323,\n",
       " 'x236': 854,\n",
       " 'x100': 3062,\n",
       " 'x102': 998,\n",
       " 'x129': 621,\n",
       " 'x9': 3451,\n",
       " 'x73': 685,\n",
       " 'x123': 2845,\n",
       " 'x61': 4562,\n",
       " 'x28': 3908,\n",
       " 'x2': 4130,\n",
       " 'x232': 1343,\n",
       " 'x255': 2507,\n",
       " 'x250': 1193,\n",
       " 'x27': 1278,\n",
       " 'x111': 1305,\n",
       " 'x124': 148,\n",
       " 'x99': 1724,\n",
       " 'x139': 711,\n",
       " 'x112': 1291,\n",
       " 'x240': 2556,\n",
       " 'x39': 4747,\n",
       " 'x237': 1682,\n",
       " 'x63': 7418,\n",
       " 'x201': 1450,\n",
       " 'x226': 4547,\n",
       " 'x147': 6104,\n",
       " 'x249': 798,\n",
       " 'x135': 3064,\n",
       " 'x140': 784,\n",
       " 'x22': 9845,\n",
       " 'x128': 3622,\n",
       " 'x159': 1784,\n",
       " 'x247': 3478,\n",
       " 'x182': 3025,\n",
       " 'x148': 253,\n",
       " 'x194': 6729,\n",
       " 'x95': 2965,\n",
       " 'x34': 1737,\n",
       " 'x46': 6469,\n",
       " 'x10': 7536,\n",
       " 'x132': 72,\n",
       " 'x161': 615,\n",
       " 'x26': 68,\n",
       " 'x86': 133,\n",
       " 'x74': 103,\n",
       " 'x131': 684,\n",
       " 'x181': 2272,\n",
       " 'x117': 522,\n",
       " 'x87': 558,\n",
       " 'x196': 291,\n",
       " 'x136': 869,\n",
       " 'x222': 530,\n",
       " 'x0': 1267,\n",
       " 'x167': 889,\n",
       " 'x75': 250,\n",
       " 'x151': 2347,\n",
       " 'x216': 205,\n",
       " 'x66': 1013,\n",
       " 'x107': 379,\n",
       " 'x94': 358,\n",
       " 'x103': 136}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_token_freq = sorted(token_dict.items(), key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x26', 68),\n",
       " ('x132', 72),\n",
       " ('x137', 84),\n",
       " ('x74', 103),\n",
       " ('x86', 133),\n",
       " ('x103', 136),\n",
       " ('x124', 148),\n",
       " ('x153', 166),\n",
       " ('x244', 171),\n",
       " ('x216', 205),\n",
       " ('x115', 216),\n",
       " ('x75', 250),\n",
       " ('x148', 253),\n",
       " ('x118', 255),\n",
       " ('x165', 277),\n",
       " ('x196', 291),\n",
       " ('x44', 297),\n",
       " ('x94', 358),\n",
       " ('x242', 367),\n",
       " ('x107', 379),\n",
       " ('x57', 384),\n",
       " ('x98', 433),\n",
       " ('x21', 436),\n",
       " ('x109', 443),\n",
       " ('x121', 454),\n",
       " ('x228', 474),\n",
       " ('x207', 480),\n",
       " ('x227', 518),\n",
       " ('x117', 522),\n",
       " ('x222', 530),\n",
       " ('x248', 531),\n",
       " ('x178', 557),\n",
       " ('x87', 558),\n",
       " ('x143', 566),\n",
       " ('x177', 576),\n",
       " ('x213', 594),\n",
       " ('x198', 605),\n",
       " ('x56', 608),\n",
       " ('x78', 614),\n",
       " ('x161', 615),\n",
       " ('x129', 621),\n",
       " ('x186', 637),\n",
       " ('x218', 646),\n",
       " ('x173', 667),\n",
       " ('x131', 684),\n",
       " ('x73', 685),\n",
       " ('x155', 701),\n",
       " ('x139', 711),\n",
       " ('x183', 746),\n",
       " ('x108', 775),\n",
       " ('x239', 780),\n",
       " ('x140', 784),\n",
       " ('x126', 796),\n",
       " ('x249', 798),\n",
       " ('x134', 814),\n",
       " ('x215', 820),\n",
       " ('x113', 826),\n",
       " ('x236', 854),\n",
       " ('x136', 869),\n",
       " ('x168', 885),\n",
       " ('x167', 889),\n",
       " ('x190', 896),\n",
       " ('x101', 974),\n",
       " ('x37', 983),\n",
       " ('x245', 988),\n",
       " ('x138', 998),\n",
       " ('x102', 998),\n",
       " ('x230', 1001),\n",
       " ('x66', 1013),\n",
       " ('x12', 1026),\n",
       " ('x202', 1028),\n",
       " ('x116', 1047),\n",
       " ('x193', 1086),\n",
       " ('x130', 1096),\n",
       " ('x224', 1123),\n",
       " ('x156', 1125),\n",
       " ('x234', 1126),\n",
       " ('x97', 1134),\n",
       " ('x105', 1167),\n",
       " ('x162', 1171),\n",
       " ('x250', 1193),\n",
       " ('x152', 1201),\n",
       " ('x84', 1202),\n",
       " ('x219', 1216),\n",
       " ('x246', 1225),\n",
       " ('x214', 1237),\n",
       " ('x0', 1267),\n",
       " ('x27', 1278),\n",
       " ('x112', 1291),\n",
       " ('x114', 1296),\n",
       " ('x125', 1298),\n",
       " ('x111', 1305),\n",
       " ('x72', 1319),\n",
       " ('x209', 1323),\n",
       " ('x232', 1343),\n",
       " ('x62', 1348),\n",
       " ('x68', 1380),\n",
       " ('x201', 1450),\n",
       " ('x15', 1457),\n",
       " ('x104', 1474),\n",
       " ('x58', 1543),\n",
       " ('x30', 1580),\n",
       " ('x252', 1623),\n",
       " ('x204', 1641),\n",
       " ('x158', 1649),\n",
       " ('x237', 1682),\n",
       " ('x99', 1724),\n",
       " ('x34', 1737),\n",
       " ('x208', 1747),\n",
       " ('x45', 1750),\n",
       " ('x106', 1755),\n",
       " ('x38', 1775),\n",
       " ('x211', 1782),\n",
       " ('x159', 1784),\n",
       " ('x76', 1801),\n",
       " ('x67', 1891),\n",
       " ('x212', 1940),\n",
       " ('x170', 2045),\n",
       " ('x187', 2165),\n",
       " ('x164', 2165),\n",
       " ('x179', 2176),\n",
       " ('x3', 2192),\n",
       " ('x199', 2242),\n",
       " ('x181', 2272),\n",
       " ('x59', 2276),\n",
       " ('x92', 2279),\n",
       " ('x133', 2295),\n",
       " ('x151', 2347),\n",
       " ('x191', 2349),\n",
       " ('x11', 2375),\n",
       " ('x5', 2387),\n",
       " ('x20', 2450),\n",
       " ('x80', 2466),\n",
       " ('x255', 2507),\n",
       " ('x197', 2532),\n",
       " ('x240', 2556),\n",
       " ('x210', 2661),\n",
       " ('x17', 2676),\n",
       " ('x217', 2681),\n",
       " ('x18', 2701),\n",
       " ('x55', 2705),\n",
       " ('x69', 2757),\n",
       " ('x174', 2829),\n",
       " ('x123', 2845),\n",
       " ('x154', 2889),\n",
       " ('x95', 2965),\n",
       " ('x81', 2968),\n",
       " ('x182', 3025),\n",
       " ('x100', 3062),\n",
       " ('x135', 3064),\n",
       " ('x203', 3080),\n",
       " ('x205', 3112),\n",
       " ('x52', 3236),\n",
       " ('x171', 3309),\n",
       " ('x43', 3327),\n",
       " ('x238', 3413),\n",
       " ('x144', 3435),\n",
       " ('x9', 3451),\n",
       " ('x247', 3478),\n",
       " ('x48', 3520),\n",
       " ('x254', 3529),\n",
       " ('x54', 3593),\n",
       " ('x14', 3604),\n",
       " ('x243', 3617),\n",
       " ('x31', 3620),\n",
       " ('x128', 3622),\n",
       " ('x32', 3624),\n",
       " ('x221', 3634),\n",
       " ('x166', 3641),\n",
       " ('x1', 3664),\n",
       " ('x192', 3670),\n",
       " ('x53', 3798),\n",
       " ('x110', 3800),\n",
       " ('x251', 3806),\n",
       " ('x60', 3809),\n",
       " ('x91', 3827),\n",
       " ('x28', 3908),\n",
       " ('x4', 3925),\n",
       " ('x172', 4081),\n",
       " ('x2', 4130),\n",
       " ('x145', 4173),\n",
       " ('x51', 4174),\n",
       " ('x41', 4212),\n",
       " ('x231', 4269),\n",
       " ('x122', 4288),\n",
       " ('x180', 4343),\n",
       " ('x189', 4497),\n",
       " ('x33', 4504),\n",
       " ('x226', 4547),\n",
       " ('x90', 4549),\n",
       " ('x61', 4562),\n",
       " ('x223', 4593),\n",
       " ('x160', 4716),\n",
       " ('x39', 4747),\n",
       " ('x82', 4780),\n",
       " ('x89', 4805),\n",
       " ('x233', 4807),\n",
       " ('x77', 4942),\n",
       " ('x7', 5019),\n",
       " ('x29', 5151),\n",
       " ('x83', 5380),\n",
       " ('x141', 5389),\n",
       " ('x142', 5508),\n",
       " ('x235', 5602),\n",
       " ('x163', 5611),\n",
       " ('x149', 5778),\n",
       " ('x65', 5800),\n",
       " ('x229', 5861),\n",
       " ('x241', 5979),\n",
       " ('x176', 5984),\n",
       " ('x96', 6018),\n",
       " ('x6', 6088),\n",
       " ('x23', 6095),\n",
       " ('x147', 6104),\n",
       " ('x150', 6239),\n",
       " ('x200', 6328),\n",
       " ('x220', 6359),\n",
       " ('x46', 6469),\n",
       " ('x64', 6497),\n",
       " ('x71', 6510),\n",
       " ('x225', 6572),\n",
       " ('x16', 6708),\n",
       " ('x194', 6729),\n",
       " ('x253', 6741),\n",
       " ('x175', 6801),\n",
       " ('x195', 6819),\n",
       " ('x47', 6936),\n",
       " ('x127', 7116),\n",
       " ('x184', 7212),\n",
       " ('x70', 7280),\n",
       " ('x63', 7418),\n",
       " ('x169', 7462),\n",
       " ('x10', 7536),\n",
       " ('x35', 7704),\n",
       " ('x188', 8060),\n",
       " ('x42', 8169),\n",
       " ('x49', 8223),\n",
       " ('x25', 8339),\n",
       " ('x40', 8365),\n",
       " ('x88', 8509),\n",
       " ('x185', 8713),\n",
       " ('x50', 8820),\n",
       " ('x146', 8966),\n",
       " ('x120', 9161),\n",
       " ('x8', 9205),\n",
       " ('x13', 9250),\n",
       " ('x24', 9302),\n",
       " ('x157', 9696),\n",
       " ('x22', 9845),\n",
       " ('x93', 9865),\n",
       " ('x206', 9981),\n",
       " ('x85', 10627),\n",
       " ('x79', 10740),\n",
       " ('x19', 12640),\n",
       " ('x36', 15414),\n",
       " ('x119', 16059)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_token_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 256 artists>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(token_dict.keys(), token_dict.values(), color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from transformers import RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [str(x) for x in Path(\"data\").glob(\"*.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(BPE())\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer()\n",
    "tokenizer.train(files=paths, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if codewords are tokenized correctly - yes!\n",
    "\n",
    "f = open(paths[2], 'r')\n",
    "text = f.read()\n",
    "output = tokenizer.encode(text)\n",
    "print(output.ids[:5])\n",
    "print(output.tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save('tokenizer/bert-tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tokenizer_info = json.load(open('tokenizer/bert-tokenizer.json', 'r'))\n",
    "\n",
    "with open('tokenizer/vocab.json', 'w') as file:\n",
    "    json.dump(tokenizer_info['model']['vocab'], file)\n",
    "\n",
    "with open('tokenizer/merges.json', 'w') as file:\n",
    "    json.dump(tokenizer_info['model']['merges'], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_load = RobertaTokenizerFast.from_pretrained('tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, tokenizer):\n",
    "\n",
    "        self.examples = []\n",
    "        # encode sequence into token ids\n",
    "        for example in df.values:\n",
    "            #x = tokenizer.encode_plus(example, truncation=True, padding=True)\n",
    "            x = tokenizer.encode_plus(example)\n",
    "            self.examples += [x.input_ids]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return torch.tensor(self.examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_val_data.csv')\n",
    "\n",
    "train_df = df[df['is_valid'] == 0]\n",
    "valid_df = df[df['is_valid'] == 1]\n",
    "\n",
    "train_dataset = CustomDataset(train_df['codewords'], tokenizer_load)\n",
    "valid_dataset = CustomDataset(valid_df['codewords'], tokenizer_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from transformers import RobertaConfig, RobertaModel, RobertaForMaskedLM\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = RobertaConfig(vocab_size=256)\n",
    "model = RobertaForMaskedLM(configuration)\n",
    "print('Num parameters: ', model.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface assumed `bert-tokenizer` was a path, a model identifier, or url to a directory containing vocabulary files named `['vocab.json', 'merges.txt']` but couldn't find such vocabulary files at this path or url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_load = RobertaTokenizerFast.from_pretrained('tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer_load, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the trainer for our model\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('BERT_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model='BERT_models',\n",
    "    tokenizer=tokenizer_load\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask(\"X23 <mask>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine-tune LM on genre classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_for_bert(data, tokenizer, max_len):\n",
    "    \n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for sent in data:\n",
    "        \n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text = sent,\n",
    "            max_length = max_len,\n",
    "            pad_to_max_length = True,\n",
    "            truncation=True,\n",
    "            return_attention_mask = True)\n",
    "        \n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "        \n",
    "        # convert lists to tensors\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_masks = torch.tensor(attention_masks)\n",
    "        \n",
    "        return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In training for genre classification, we take the list of codewords for one audio clip as one senetence. \n",
    "\n",
    "we need to find the maximum length of our sentences from all of the codeword representations of the GTZAN dataset, which is MAX_LEN.\n",
    "\n",
    "* what form should `sent` be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the maximum length of sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data = pd.read_csv('train_val_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "all_codewords = np.concatenate([train_val_data['codewords'].values, \n",
    "               test_data['codewords'].values])\n",
    "\n",
    "print(f\"Total number of 'sentences': {all_codewords.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(sent) for sent in all_codewords])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize our data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = train_val_data['codewords'][0]\n",
    "encoded = preprocess_for_bert(original, tokenizer_load, max_len)\n",
    "print(f'Original: {original}\\nEncode: {encoded}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_val_data[(train_val_data['is_valid']==0)]['codewords'].values\n",
    "X_val = train_val_data[(train_val_data['is_valid']==1)]['codewords'].values\n",
    "\n",
    "y_train = train_val_data[(train_val_data['is_valid']==0)]['genre'].values\n",
    "y_val = train_val_data[(train_val_data['is_valid']==1)]['genre'].values\n",
    "\n",
    "train_inputs, train_masks = preprocess_for_bert(X_train, tokenizer_load, max_len)\n",
    "val_inputs, val_masks = preprocess_for_bert(X_val, tokenizer_load, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Pytorch DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import pandas as pd\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = one_hot_encode(train_val_data[train_val_data['is_valid']==0], 'genre')\n",
    "y_val = one_hot_encode(train_val_data[train_val_data['is_valid']==1], 'genre')\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "print(train_labels, '\\n', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader for training set\n",
    "# train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "print(train_inputs.shape, train_masks.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create BERT classifier for genre identification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, tokenizer, free_bert=False):\n",
    "        \n",
    "        super(BertClassifier, self).__init__()\n",
    "        D_in, H, D_out = 768, 50, 10\n",
    "        self.bert = RobertaTokenizerFast.from_pretrained('tokenizer')\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        # get outputs from Bert\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        # extract the last hidden state for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "        \n",
    "        # compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(epochs=4):\n",
    "\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
